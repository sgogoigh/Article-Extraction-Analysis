{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b68d1e4-1cc6-40df-9882-fdf0ea00669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import string\n",
    "import logging\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, opinion_lexicon\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4cb260a-0d26-424b-ae7b-3e16a3b987b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sgogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sgogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     C:\\Users\\sgogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sgogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('opinion_lexicon')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cfe0ed1-d48a-4b02-867f-5f00cb73fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wordlist(path: str) -> List[str]:\n",
    "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        lines = [l.strip() for l in f if l.strip() and not l.startswith(';')]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b86ba1f0-da51-437b-b151-d0e5a5e9eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_negative_dicts(master_dir='MasterDictionary'):\n",
    "    pos = []\n",
    "    neg = []\n",
    "    pos_path = os.path.join(master_dir, 'positive-words.txt')\n",
    "    neg_path = os.path.join(master_dir, 'negative-words.txt')\n",
    "    logging.info(\"Loading positive/negative lists from MasterDictionary folder.\")\n",
    "    pos = load_wordlist(pos_path)\n",
    "    neg = load_wordlist(neg_path)\n",
    "    pos_set = set(w.lower() for w in pos)\n",
    "    neg_set = set(w.lower() for w in neg)\n",
    "    return pos_set, neg_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddd9abeb-dabd-4f1b-8c3e-fe18a256d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords_set(stopwords_dir='StopWords'):\n",
    "    sw = set()\n",
    "    if os.path.isdir(stopwords_dir):\n",
    "        files = [os.path.join(stopwords_dir, f) for f in os.listdir(stopwords_dir) if os.path.isfile(os.path.join(stopwords_dir, f))]\n",
    "        if files:\n",
    "            logging.info(\"Loading stopwords from StopWords folder.\")\n",
    "            for fpath in files:\n",
    "                try:\n",
    "                    for w in load_wordlist(fpath):\n",
    "                        sw.add(w.lower())\n",
    "                except Exception:\n",
    "                    continue\n",
    "    return sw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db4c4a03-afd7-4bde-869f-838f3b346df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article_text(url: str) -> Tuple[str, str]:\n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=15)\n",
    "        if r.status_code != 200:\n",
    "            logging.warning(f\"URL {url} returned status {r.status_code}.\")\n",
    "            return \"\", \"\"\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "        title = \"\"\n",
    "        h1 = soup.find('h1')\n",
    "        if h1 and h1.get_text(strip=True):\n",
    "            title = h1.get_text(strip=True)\n",
    "        elif soup.find('meta', property='og:title'):\n",
    "            title = soup.find('meta', property='og:title').get('content', '').strip()\n",
    "        elif soup.title and soup.title.string:\n",
    "            title = soup.title.string.strip()\n",
    "\n",
    "        body = \"\"\n",
    "        article_tag = soup.find('article')\n",
    "        if article_tag:\n",
    "            paragraphs = []\n",
    "            for elem in article_tag.find_all(['h2', 'h3', 'p']):\n",
    "                text = elem.get_text(separator=\"\\n\", strip=True)\n",
    "                if text:\n",
    "                    paragraphs.append(text)\n",
    "            if paragraphs:\n",
    "                body = \"\\n\".join(paragraphs)\n",
    "\n",
    "        if not body:\n",
    "            candidates = []\n",
    "            for div in soup.find_all(['div', 'section'], recursive=True):\n",
    "                ps = div.find_all('p')\n",
    "                if len(ps) >= 3:\n",
    "                    text = \"\\n\".join(p.get_text(separator=\"\\n\", strip=True) for p in ps if p.get_text(strip=True))\n",
    "                    candidates.append((len(ps), text))\n",
    "            if candidates:\n",
    "                candidates.sort(key=lambda x: x[0], reverse=True)\n",
    "                body = \"\\n\".join([p.strip() for p in candidates[0][1].split(\"\\n\") if p.strip()])\n",
    "\n",
    "        if not body:\n",
    "            ps = soup.find_all('p')\n",
    "            if ps:\n",
    "                body = \"\\n\".join(p.get_text(separator=\"\\n\", strip=True) for p in ps if p.get_text(strip=True))\n",
    "\n",
    "        if body:\n",
    "            lines = [line.strip() for line in body.splitlines() if line.strip() and len(line.strip()) > 20]\n",
    "            body = \"\\n\".join(lines)\n",
    "            body = clean_text(body)\n",
    "\n",
    "        return title, body\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Exception while extracting {url}: {e}\")\n",
    "        return \"\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa50eb2-2721-4979-a5f8-d70c3282c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word: str) -> int:\n",
    "    w = word.lower()\n",
    "    w = re.sub(r'[^a-z]', '', w)\n",
    "    if not w:\n",
    "        return 0\n",
    "    groups = re.findall(r'[aeiouy]+', w)\n",
    "    syllables = len(groups)\n",
    "    if w.endswith(\"es\") or w.endswith(\"ed\"):\n",
    "        if syllables > 1:\n",
    "            syllables -= 1\n",
    "    if w.endswith(\"e\") and not w.endswith(\"le\"):\n",
    "        # silent e\n",
    "        if syllables > 1:\n",
    "            syllables -= 1\n",
    "    if syllables == 0:\n",
    "        syllables = 1\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6fc606e-12f4-4785-86cc-adf959a91b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSONAL_PRONOUNS_PATTERN = re.compile(r'\\b(I|we|We|WE|my|My|our|Our|ours|Ours|us|Us)\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f11d0e4c-34b6-4deb-9881-68149de77940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize(text: str):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = []\n",
    "    for sent in sentences:\n",
    "        for token in word_tokenize(sent):\n",
    "            token = token.strip()\n",
    "            if token:\n",
    "                words.append(token)\n",
    "    return sentences, words\n",
    "\n",
    "\n",
    "def is_alpha_word(w: str) -> bool:\n",
    "    return bool(re.match(r'^[A-Za-z]+$', w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8163238-62b0-4374-b5a1-2c1b9d76bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text: str,\n",
    "                 pos_set: set,\n",
    "                 neg_set: set,\n",
    "                 stopwords_set: set):\n",
    "    raw_text = text or \"\"\n",
    "    if not raw_text.strip():\n",
    "        return {\n",
    "            'POSITIVE SCORE': 0,\n",
    "            'NEGATIVE SCORE': 0,\n",
    "            'POLARITY SCORE': 0.0,\n",
    "            'SUBJECTIVITY SCORE': 0.0,\n",
    "            'AVG SENTENCE LENGTH': 0.0,\n",
    "            'PERCENTAGE OF COMPLEX WORDS': 0.0,\n",
    "            'FOG INDEX': 0.0,\n",
    "            'AVG NUMBER OF WORDS PER SENTENCE': 0.0,\n",
    "            'COMPLEX WORD COUNT': 0,\n",
    "            'WORD COUNT': 0,\n",
    "            'SYLLABLE PER WORD': 0.0,\n",
    "            'PERSONAL PRONOUNS': 0,\n",
    "            'AVG WORD LENGTH': 0.0\n",
    "        }\n",
    "\n",
    "    sentences = sent_tokenize(raw_text)\n",
    "    total_sentences = len(sentences) if sentences else 1\n",
    "\n",
    "    raw_tokens = []\n",
    "    for s in sentences:\n",
    "        raw_tokens.extend(word_tokenize(s))\n",
    "    tokens_cleaned = []\n",
    "    for t in raw_tokens:\n",
    "        t_stripped = t.strip(string.punctuation)\n",
    "        if t_stripped:\n",
    "            tokens_cleaned.append(t_stripped)\n",
    "\n",
    "    cleaned_words = [w for w in [w.lower() for w in tokens_cleaned] if w not in stopwords_set and is_alpha_word(w)]\n",
    "    total_words_after_cleaning = len(cleaned_words)\n",
    "    \n",
    "    pos_score = sum(1 for w in cleaned_words if w in pos_set)\n",
    "    neg_score = sum(1 for w in cleaned_words if w in neg_set)\n",
    "    \n",
    "    negative_score = neg_score\n",
    "    positive_score = pos_score\n",
    "\n",
    "    polarity_score = 0.0\n",
    "    if (positive_score + negative_score) != 0:\n",
    "        polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 1e-6)\n",
    "\n",
    "    subjectivity_score = (positive_score + negative_score) / (total_words_after_cleaning + 1e-6)\n",
    "\n",
    "    word_count = total_words_after_cleaning\n",
    "\n",
    "    syllable_counts = [count_syllables(w) for w in cleaned_words]\n",
    "    total_syllables = sum(syllable_counts)\n",
    "    complex_word_count = sum(1 for s in syllable_counts if s > 2)\n",
    "\n",
    "    avg_sentence_length = (word_count / total_sentences) if total_sentences > 0 else 0.0\n",
    "\n",
    "    percentage_complex_words = (complex_word_count / word_count) if word_count > 0 else 0.0\n",
    "\n",
    "    fog_index = 0.4 * (avg_sentence_length + (percentage_complex_words))\n",
    "\n",
    "    avg_words_per_sentence = avg_sentence_length\n",
    "\n",
    "    syllable_per_word = (total_syllables / word_count) if word_count > 0 else 0.0\n",
    "\n",
    "    pronoun_matches = re.findall(PERSONAL_PRONOUNS_PATTERN, raw_text)\n",
    "    personal_pronouns = 0\n",
    "    for m in pronoun_matches:\n",
    "        if m.upper() == 'US' and m.isupper():\n",
    "            continue\n",
    "        personal_pronouns += 1\n",
    "\n",
    "    total_chars = sum(len(w) for w in cleaned_words)\n",
    "    avg_word_length = (total_chars / word_count) if word_count > 0 else 0.0\n",
    "\n",
    "    result = {\n",
    "        'POSITIVE SCORE': positive_score,\n",
    "        'NEGATIVE SCORE': negative_score,\n",
    "        'POLARITY SCORE': polarity_score,\n",
    "        'SUBJECTIVITY SCORE': subjectivity_score,\n",
    "        'AVG SENTENCE LENGTH': avg_sentence_length,\n",
    "        'PERCENTAGE OF COMPLEX WORDS': percentage_complex_words,\n",
    "        'FOG INDEX': fog_index,\n",
    "        'AVG NUMBER OF WORDS PER SENTENCE': avg_words_per_sentence,\n",
    "        'COMPLEX WORD COUNT': complex_word_count,\n",
    "        'WORD COUNT': word_count,\n",
    "        'SYLLABLE PER WORD': syllable_per_word,\n",
    "        'PERSONAL PRONOUNS': personal_pronouns,\n",
    "        'AVG WORD LENGTH': avg_word_length\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13c2246a-1833-4906-8da8-3861221f8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_columns(df: pd.DataFrame):\n",
    "    cols = list(df.columns)\n",
    "    url_col = None\n",
    "    id_col = None\n",
    "    for c in cols:\n",
    "        if c.lower() in ('url', 'link', 'article_link', 'article url', 'article_link'):\n",
    "            url_col = c\n",
    "        if c.lower() in ('url_id', 'id', 'urlid', 'identifier'):\n",
    "            id_col = c\n",
    "   \n",
    "    if url_col is None:\n",
    "        for c in cols:\n",
    "            if df[c].astype(str).str.startswith('http').any():\n",
    "                url_col = c\n",
    "                break\n",
    "    if id_col is None:\n",
    "        candidates = [c for c in cols if c != url_col]\n",
    "        if candidates:\n",
    "            id_col = candidates[0]\n",
    "    return url_col, id_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15fef1b7-b7ed-4582-8158-ae6e95d2cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(raw):\n",
    "    import re\n",
    "    txt = raw.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    \n",
    "    txt = re.sub(r'\\n{3,}', '\\n\\n', txt)\n",
    "    \n",
    "    lines = txt.splitlines()\n",
    "    cleaned_lines = []\n",
    "    prev = None\n",
    "    for line in lines:\n",
    "        if line.strip() == prev:\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "        prev = line.strip()\n",
    "    txt = '\\n'.join(cleaned_lines)\n",
    "    \n",
    "    txt = re.sub(r'(^[A-Z][A-Za-z0-9\\-\\s]{3,60}\\n)([A-Z])', lambda m: m.group(1) + '\\n' + m.group(2), txt, flags=re.M)\n",
    "    txt = re.sub(r'((?:- .+\\n){3,})\\1+', r'\\1', txt)\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7228f011-0d7f-4ecf-9820-d98d08456464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_xlsx='Input.xlsx', output_xlsx='Output.xlsx', output_csv='Output.csv'):\n",
    "    if not os.path.exists(input_xlsx):\n",
    "        logging.error(f\"{input_xlsx} not found in CWD. Place the provided Input.xlsx in the working directory.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    df_input = pd.read_excel(input_xlsx)\n",
    "    if df_input.empty:\n",
    "        logging.error(\"Input.xlsx appears empty.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    url_col, id_col = find_columns(df_input)\n",
    "    if url_col is None:\n",
    "        logging.error(\"Could not detect URL column in Input.xlsx. Ensure there's a column containing URLs.\")\n",
    "        sys.exit(1)\n",
    "    if id_col is None:\n",
    "        logging.error(\"Could not detect URL_ID column. Ensure Input.xlsx contains an identifier column.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Prepare dictionaries and stopwords\n",
    "    pos_set, neg_set = get_positive_negative_dicts()\n",
    "    stopwords_set = get_stopwords_set()\n",
    "\n",
    "    # Prepare results list\n",
    "    results = []\n",
    "    # preserve all input columns first as required\n",
    "    for idx, row in df_input.iterrows():\n",
    "        url = str(row[url_col]).strip()\n",
    "        url_id = str(row[id_col]).strip()\n",
    "        logging.info(f\"Processing row {idx+1}: URL_ID={url_id} URL={url}\")\n",
    "\n",
    "        title, body = (\"\",\"\")\n",
    "        if url.lower().startswith('http'):\n",
    "            title, body = extract_article_text(url)\n",
    "            article_text = (title + \"\\n\\n\" + body).strip()\n",
    "            article_text = clean_text(article_text)\n",
    "            if not title and not body:\n",
    "                logging.warning(f\"No content extracted for {url}. Possibly JS heavy; consider using Selenium.\")\n",
    "        else:\n",
    "            logging.warning(f\"URL value doesn't look like a URL: {url}\")\n",
    "\n",
    "        # Save extracted to text file named by URL_ID\n",
    "        safe_name = re.sub(r'[^\\w\\-_.]', '_', url_id) or f'url_{idx+1}'\n",
    "        txt_filename = f\"{safe_name}.txt\"\n",
    "\n",
    "        output_folder = os.path.join(os.getcwd(), \"TextStore\")\n",
    "        output_path = os.path.join(output_folder, txt_filename)\n",
    "        with open(output_path, 'w', encoding='utf-8') as outf:\n",
    "            if article_text:\n",
    "                outf.write(article_text)\n",
    "        logging.info(f\"Saved extracted article to {txt_filename}\")\n",
    "\n",
    "\n",
    "        analysis = analyze_text(body, pos_set, neg_set, stopwords_set)\n",
    "\n",
    "        out_row = {}\n",
    "        for c in df_input.columns:\n",
    "            out_row[c] = row[c]\n",
    "\n",
    "        out_row['POSITIVE SCORE'] = analysis['POSITIVE SCORE']\n",
    "        out_row['NEGATIVE SCORE'] = analysis['NEGATIVE SCORE']\n",
    "        out_row['POLARITY SCORE'] = analysis['POLARITY SCORE']\n",
    "        out_row['SUBJECTIVITY SCORE'] = analysis['SUBJECTIVITY SCORE']\n",
    "        out_row['AVG SENTENCE LENGTH'] = analysis['AVG SENTENCE LENGTH']\n",
    "        out_row['PERCENTAGE OF COMPLEX WORDS'] = analysis['PERCENTAGE OF COMPLEX WORDS']\n",
    "        out_row['FOG INDEX'] = analysis['FOG INDEX']\n",
    "        out_row['AVG NUMBER OF WORDS PER SENTENCE'] = analysis['AVG NUMBER OF WORDS PER SENTENCE']\n",
    "        out_row['COMPLEX WORD COUNT'] = analysis['COMPLEX WORD COUNT']\n",
    "        out_row['WORD COUNT'] = analysis['WORD COUNT']\n",
    "        out_row['SYLLABLE PER WORD'] = analysis['SYLLABLE PER WORD']\n",
    "        out_row['PERSONAL PRONOUNS'] = analysis['PERSONAL PRONOUNS']\n",
    "        out_row['AVG WORD LENGTH'] = analysis['AVG WORD LENGTH']\n",
    "\n",
    "        results.append(out_row)\n",
    "\n",
    "    out_df = pd.DataFrame(results)\n",
    "    ordered_cols = list(df_input.columns) + [\n",
    "        'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE',\n",
    "        'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX',\n",
    "        'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
    "        'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH'\n",
    "    ]\n",
    "    \n",
    "    ordered_cols = [c for c in ordered_cols if c in out_df.columns]\n",
    "    out_df = out_df[ordered_cols]\n",
    "    out_df.to_csv(output_csv, index=False)\n",
    "    out_df.to_excel(output_xlsx, index=False)\n",
    "    logging.info(f\"Saved outputs to {output_csv} and {output_xlsx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "454e6db4-9e4e-402a-b9d9-bebdf1c90d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Loading positive/negative lists from MasterDictionary folder.\n",
      "[INFO] Loading stopwords from StopWords folder.\n",
      "[INFO] Processing row 1: URL_ID=Netclan20241017 URL=https://insights.blackcoffer.com/ai-and-ml-based-youtube-analytics-and-content-creation-tool-for-optimizing-subscriber-engagement-and-content-strategy/\n",
      "[INFO] Saved extracted article to Netclan20241017.txt\n",
      "[INFO] Processing row 2: URL_ID=Netclan20241018 URL=https://insights.blackcoffer.com/enhancing-front-end-features-and-functionality-for-improved-user-experience-and-dashboard-accuracy-in-partner-hospital-application/\n",
      "[INFO] Saved extracted article to Netclan20241018.txt\n",
      "[INFO] Processing row 3: URL_ID=Netclan20241019 URL=https://insights.blackcoffer.com/roas-dashboard-for-campaign-wise-google-ads-budget-tracking-using-google-ads-ap/\n",
      "[INFO] Saved extracted article to Netclan20241019.txt\n",
      "[INFO] Processing row 4: URL_ID=Netclan20241020 URL=https://insights.blackcoffer.com/efficient-processing-and-analysis-of-financial-data-from-pdf-files-addressing-formatting-inconsistencies-and-ensuring-data-integrity-for-a-toyota-dealership-management-firm/\n",
      "[INFO] Saved extracted article to Netclan20241020.txt\n",
      "[INFO] Processing row 5: URL_ID=Netclan20241021 URL=https://insights.blackcoffer.com/development-of-ea-robot-for-automated-trading/\n",
      "[INFO] Saved extracted article to Netclan20241021.txt\n",
      "[INFO] Processing row 6: URL_ID=Netclan20241022 URL=https://insights.blackcoffer.com/ai-and-ml-based-youtube-analytics-and-content-creation-tool-for-optimizing-subscriber-engagement-and-content-strategy/\n",
      "[INFO] Saved extracted article to Netclan20241022.txt\n",
      "[INFO] Processing row 7: URL_ID=Netclan20241023 URL=https://insights.blackcoffer.com/enhancing-front-end-features-and-functionality-for-improved-user-experience-and-dashboard-accuracy-in-partner-hospital-application/\n",
      "[INFO] Saved extracted article to Netclan20241023.txt\n",
      "[INFO] Processing row 8: URL_ID=Netclan20241024 URL=https://insights.blackcoffer.com/roas-dashboard-for-campaign-wise-google-ads-budget-tracking-using-google-ads-ap/\n",
      "[INFO] Saved extracted article to Netclan20241024.txt\n",
      "[INFO] Processing row 9: URL_ID=Netclan20241025 URL=https://insights.blackcoffer.com/efficient-processing-and-analysis-of-financial-data-from-pdf-files-addressing-formatting-inconsistencies-and-ensuring-data-integrity-for-a-toyota-dealership-management-firm/\n",
      "[INFO] Saved extracted article to Netclan20241025.txt\n",
      "[INFO] Processing row 10: URL_ID=Netclan20241026 URL=https://insights.blackcoffer.com/transforming-and-managing-a-large-scale-sql-pedigree-database-to-neo4j-graph-db/\n",
      "[INFO] Saved extracted article to Netclan20241026.txt\n",
      "[INFO] Processing row 11: URL_ID=Netclan20241027 URL=https://insights.blackcoffer.com/enhancing-model-accuracy-from-58-to-over-90-strategies-for-improving-predictive-performance/\n",
      "[INFO] Saved extracted article to Netclan20241027.txt\n",
      "[INFO] Processing row 12: URL_ID=Netclan20241028 URL=https://insights.blackcoffer.com/securing-sensitive-financial-data-with-privacy-preserving-machine-learning-for-predictive-analytics/\n",
      "[INFO] Saved extracted article to Netclan20241028.txt\n",
      "[INFO] Processing row 13: URL_ID=Netclan20241029 URL=https://insights.blackcoffer.com/enhancing-data-collection-for-research-institutions-addressing-survey-fatigue-and-incorporating-verbal-communication-for-richer-insights/\n",
      "[INFO] Saved extracted article to Netclan20241029.txt\n",
      "[INFO] Processing row 14: URL_ID=Netclan20241030 URL=https://insights.blackcoffer.com/analyzing-the-impact-of-positive-emotions-and-pandemic-severity-on-mental-health-and-resilience-among-entrepreneurs-insights-and-predictive-modeling/\n",
      "[INFO] Saved extracted article to Netclan20241030.txt\n",
      "[INFO] Processing row 15: URL_ID=Netclan20241031 URL=https://insights.blackcoffer.com/dynamic-brand-centric-dashboard-for-automotive-dealerships-pdf-to-financial-insights-with-flask-react-architecture-and-aws-cloud-hosting/\n",
      "[INFO] Saved extracted article to Netclan20241031.txt\n",
      "[INFO] Processing row 16: URL_ID=Netclan20241032 URL=https://insights.blackcoffer.com/cloud-based-data-modeling-and-analysis-platform-with-drag-and-drop-interface-and-openai-api-integration-for-simulation-insights/\n",
      "[INFO] Saved extracted article to Netclan20241032.txt\n",
      "[INFO] Processing row 17: URL_ID=Netclan20241033 URL=https://insights.blackcoffer.com/voter-profile-analysis-and-search-application-for-targeted-campaign-engagement-using-government-voter-data/\n",
      "[INFO] Saved extracted article to Netclan20241033.txt\n",
      "[INFO] Processing row 18: URL_ID=Netclan20241034 URL=https://insights.blackcoffer.com/bert-based-classification-of-individuals-and-organizations-into-two-categories-using-natural-language-processing/\n",
      "[INFO] Saved extracted article to Netclan20241034.txt\n",
      "[INFO] Processing row 19: URL_ID=Netclan20241035 URL=https://insights.blackcoffer.com/comprehensive-analysis-of-solana-and-ethereum-contributors-using-github-api-with-comparative-study-of-1000-random-github-profiles/\n",
      "[INFO] Saved extracted article to Netclan20241035.txt\n",
      "[INFO] Processing row 20: URL_ID=Netclan20241036 URL=https://insights.blackcoffer.com/powerbi-rest-api-fetching-dataflow-and-refresh-schedules-with-semantic-models/\n",
      "[INFO] Saved extracted article to Netclan20241036.txt\n",
      "[INFO] Processing row 21: URL_ID=Netclan20241037 URL=https://insights.blackcoffer.com/automated-job-data-import-and-management-solution-for-enhanced-efficiency/\n",
      "[INFO] Saved extracted article to Netclan20241037.txt\n",
      "[INFO] Processing row 22: URL_ID=Netclan20241038 URL=https://insights.blackcoffer.com/data-analytics-and-optimization-solution-for-enhancing-renewable-energy-efficiency/\n",
      "[INFO] Saved extracted article to Netclan20241038.txt\n",
      "[INFO] Processing row 23: URL_ID=Netclan20241039 URL=https://insights.blackcoffer.com/time-series-analysis-and-trend-forecasting-solution-for-predicting-news-trends/\n",
      "[INFO] Saved extracted article to Netclan20241039.txt\n",
      "[INFO] Processing row 24: URL_ID=Netclan20241040 URL=https://insights.blackcoffer.com/advanced-data-visualization-solutions-for-monitoring-key-business-metrics-with-integrated-interactive-dashboards/\n",
      "[INFO] Saved extracted article to Netclan20241040.txt\n",
      "[INFO] Processing row 25: URL_ID=Netclan20241041 URL=https://insights.blackcoffer.com/advanced-patient-data-analysis-solution-for-trend-identification-and-improved-healthcare-outcome/\n",
      "[INFO] Saved extracted article to Netclan20241041.txt\n",
      "[INFO] Processing row 26: URL_ID=Netclan20241042 URL=https://insights.blackcoffer.com/anomaly-detection-and-analysis-for-enhanced-data-integrity-and-user-experience-on-bright-datas-website/\n",
      "[INFO] Saved extracted article to Netclan20241042.txt\n",
      "[INFO] Processing row 27: URL_ID=Netclan20241043 URL=https://insights.blackcoffer.com/building-custom-tflite-models-and-benchmarking-on-voxl2-chips/\n",
      "[INFO] Saved extracted article to Netclan20241043.txt\n",
      "[INFO] Processing row 28: URL_ID=Netclan20241044 URL=https://insights.blackcoffer.com/sports-prediction-model-for-multiple-sports-leagues/\n",
      "[INFO] Saved extracted article to Netclan20241044.txt\n",
      "[INFO] Processing row 29: URL_ID=Netclan20241045 URL=https://insights.blackcoffer.com/efficient-coach-allocation-system-for-sports-coaching-organization/\n",
      "[INFO] Saved extracted article to Netclan20241045.txt\n",
      "[INFO] Processing row 30: URL_ID=Netclan20241046 URL=https://insights.blackcoffer.com/data-studio-dashboard-with-a-data-pipeline-tool-synced-with-podio-using-custom-webhooks-and-google-cloud-function-2/\n",
      "[INFO] Saved extracted article to Netclan20241046.txt\n",
      "[INFO] Processing row 31: URL_ID=Netclan20241047 URL=https://insights.blackcoffer.com/ai-driven-backend-for-audio-to-text-conversion-and-analytical-assessment-in-pharmaceutical-practice/\n",
      "[INFO] Saved extracted article to Netclan20241047.txt\n",
      "[INFO] Processing row 32: URL_ID=Netclan20241048 URL=https://insights.blackcoffer.com/cloud-based-web-application-for-financial-data-processing-and-visualization-of-sp-500-metrics/\n",
      "[INFO] Saved extracted article to Netclan20241048.txt\n",
      "[INFO] Processing row 33: URL_ID=Netclan20241049 URL=https://insights.blackcoffer.com/department-wise-kpi-tracking-dashboard-with-technician-performance-analysis-for-atoz-dependable-service/\n",
      "[INFO] Saved extracted article to Netclan20241049.txt\n",
      "[INFO] Processing row 34: URL_ID=Netclan20241050 URL=https://insights.blackcoffer.com/steps-to-convert-a-node-js-api-to-python-for-aws-lambda-deployment/\n",
      "[INFO] Saved extracted article to Netclan20241050.txt\n",
      "[INFO] Processing row 35: URL_ID=Netclan20241051 URL=https://insights.blackcoffer.com/building-an-analytics-dashboard-with-a-pdf-parsing-pipeline-for-data-extraction/\n",
      "[INFO] Saved extracted article to Netclan20241051.txt\n",
      "[INFO] Processing row 36: URL_ID=Netclan20241052 URL=https://insights.blackcoffer.com/building-a-real-time-log-file-visualization-dashboard-in-kibana/\n",
      "[INFO] Saved extracted article to Netclan20241052.txt\n",
      "[INFO] Processing row 37: URL_ID=Netclan20241053 URL=https://insights.blackcoffer.com/analyzing-the-impact-of-female-ceo-appointments-on-company-stock-prices/\n",
      "[INFO] Saved extracted article to Netclan20241053.txt\n",
      "[INFO] Processing row 38: URL_ID=Netclan20241054 URL=https://insights.blackcoffer.com/ai-chatbot-using-llm-langchain-llama/\n",
      "[INFO] Saved extracted article to Netclan20241054.txt\n",
      "[INFO] Processing row 39: URL_ID=Netclan20241055 URL=https://insights.blackcoffer.com/healthcare-ai-chatbot-using-llama-llm-langchain/\n",
      "[INFO] Saved extracted article to Netclan20241055.txt\n",
      "[INFO] Processing row 40: URL_ID=Netclan20241056 URL=https://insights.blackcoffer.com/ai-bot-audio-to-audio/\n",
      "[INFO] Saved extracted article to Netclan20241056.txt\n",
      "[INFO] Processing row 41: URL_ID=Netclan20241057 URL=https://insights.blackcoffer.com/recommendation-engine-for-insurance-sector-to-expand-business-in-the-rural-area/\n",
      "[INFO] Saved extracted article to Netclan20241057.txt\n",
      "[INFO] Processing row 42: URL_ID=Netclan20241058 URL=https://insights.blackcoffer.com/data-from-crm-via-zapier-to-google-sheets-dynamic-to-powerbi/\n",
      "[INFO] Saved extracted article to Netclan20241058.txt\n",
      "[INFO] Processing row 43: URL_ID=Netclan20241059 URL=https://insights.blackcoffer.com/data-warehouse-to-google-data-studio-looker-dashboard/\n",
      "[INFO] Saved extracted article to Netclan20241059.txt\n",
      "[INFO] Processing row 44: URL_ID=Netclan20241060 URL=https://insights.blackcoffer.com/crm-monday-com-via-zapier-to-power-bi-dashboard/\n",
      "[INFO] Saved extracted article to Netclan20241060.txt\n",
      "[INFO] Processing row 45: URL_ID=Netclan20241061 URL=https://insights.blackcoffer.com/monday-com-to-kpi-dashboard-to-manage-view-and-generate-insights-from-the-crm-data/\n",
      "[INFO] Saved extracted article to Netclan20241061.txt\n",
      "[INFO] Processing row 46: URL_ID=Netclan20241062 URL=https://insights.blackcoffer.com/data-management-for-a-political-saas-application/\n",
      "[INFO] Saved extracted article to Netclan20241062.txt\n",
      "[INFO] Processing row 47: URL_ID=Netclan20241063 URL=https://insights.blackcoffer.com/google-lsa-ads-google-local-service-ads-etl-tools-and-dashboards/\n",
      "[INFO] Saved extracted article to Netclan20241063.txt\n",
      "[INFO] Processing row 48: URL_ID=Netclan20241064 URL=https://insights.blackcoffer.com/ad-networks-marketing-campaign-data-dashboard-in-looker-google-data-studio/\n",
      "[INFO] Saved extracted article to Netclan20241064.txt\n",
      "[INFO] Processing row 49: URL_ID=Netclan20241065 URL=https://insights.blackcoffer.com/analytical-solution-for-a-tech-firm/\n",
      "[INFO] Saved extracted article to Netclan20241065.txt\n",
      "[INFO] Processing row 50: URL_ID=Netclan20241066 URL=https://insights.blackcoffer.com/ai-solution-for-a-technology-information-and-internet-firm/\n",
      "[INFO] Saved extracted article to Netclan20241066.txt\n",
      "[INFO] Processing row 51: URL_ID=Netclan20241067 URL=https://insights.blackcoffer.com/ai-and-nlp-based-solutions-to-automate-data-discovery-for-venture-capital-and-private-equity-principals/\n",
      "[INFO] Saved extracted article to Netclan20241067.txt\n",
      "[INFO] Processing row 52: URL_ID=Netclan20241068 URL=https://insights.blackcoffer.com/an-etl-solution-for-an-internet-publishing-firm/\n",
      "[INFO] Saved extracted article to Netclan20241068.txt\n",
      "[INFO] Processing row 53: URL_ID=Netclan20241069 URL=https://insights.blackcoffer.com/ai-based-algorithmic-trading-bot-for-forex/\n",
      "[INFO] Saved extracted article to Netclan20241069.txt\n",
      "[INFO] Processing row 54: URL_ID=Netclan20241070 URL=https://insights.blackcoffer.com/equity-waterfalls-model-based-saas-application-for-real-estate-sector/\n",
      "[INFO] Saved extracted article to Netclan20241070.txt\n",
      "[INFO] Processing row 55: URL_ID=Netclan20241071 URL=https://insights.blackcoffer.com/ai-solutions-for-foreign-exchange-an-automated-algo-trading-tool/\n",
      "[INFO] Saved extracted article to Netclan20241071.txt\n",
      "[INFO] Processing row 56: URL_ID=Netclan20241072 URL=https://insights.blackcoffer.com/ai-agent-development-and-deployment-in-jina-ai/\n",
      "[INFO] Saved extracted article to Netclan20241072.txt\n",
      "[INFO] Processing row 57: URL_ID=Netclan20241073 URL=https://insights.blackcoffer.com/golden-record-a-knowledge-graph-database-approach-to-unfold-discovery-using-neo4j/\n",
      "[INFO] Saved extracted article to Netclan20241073.txt\n",
      "[INFO] Processing row 58: URL_ID=Netclan20241074 URL=https://insights.blackcoffer.com/advanced-ai-for-trading-automation/\n",
      "[INFO] Saved extracted article to Netclan20241074.txt\n",
      "[INFO] Processing row 59: URL_ID=Netclan20241075 URL=https://insights.blackcoffer.com/create-a-knowledge-graph-to-provide-real-time-analytics-recommendations-and-a-single-source-of-truth/\n",
      "[INFO] Saved extracted article to Netclan20241075.txt\n",
      "[INFO] Processing row 60: URL_ID=Netclan20241076 URL=https://insights.blackcoffer.com/advanced-ai-for-thermal-person-detection/\n",
      "[INFO] Saved extracted article to Netclan20241076.txt\n",
      "[INFO] Processing row 61: URL_ID=Netclan20241077 URL=https://insights.blackcoffer.com/advanced-ai-for-road-cam-threat-detection/\n",
      "[INFO] Saved extracted article to Netclan20241077.txt\n",
      "[INFO] Processing row 62: URL_ID=Netclan20241078 URL=https://insights.blackcoffer.com/advanced-ai-for-pedestrian-crossing-safety/\n",
      "[INFO] Saved extracted article to Netclan20241078.txt\n",
      "[INFO] Processing row 63: URL_ID=Netclan20241079 URL=https://insights.blackcoffer.com/handgun-detection-using-yolo/\n",
      "[INFO] Saved extracted article to Netclan20241079.txt\n",
      "[INFO] Processing row 64: URL_ID=Netclan20241080 URL=https://insights.blackcoffer.com/using-graph-technology-to-create-single-customer-view/\n",
      "[INFO] Saved extracted article to Netclan20241080.txt\n",
      "[INFO] Processing row 65: URL_ID=Netclan20241081 URL=https://insights.blackcoffer.com/car-detection-in-satellite-images/\n",
      "[INFO] Saved extracted article to Netclan20241081.txt\n",
      "[INFO] Processing row 66: URL_ID=Netclan20241082 URL=https://insights.blackcoffer.com/building-a-physics-informed-neural-network-for-circuit-evaluation/\n",
      "[INFO] Saved extracted article to Netclan20241082.txt\n",
      "[INFO] Processing row 67: URL_ID=Netclan20241083 URL=https://insights.blackcoffer.com/connecting-mongodb-database-to-power-bi-dashboard-dashboard-automation/\n",
      "[INFO] Saved extracted article to Netclan20241083.txt\n",
      "[INFO] Processing row 68: URL_ID=Netclan20241084 URL=https://insights.blackcoffer.com/data-transformation/\n",
      "[INFO] Saved extracted article to Netclan20241084.txt\n",
      "[INFO] Processing row 69: URL_ID=Netclan20241085 URL=https://insights.blackcoffer.com/e-commerce-store-analysis-purchase-behavior-ad-spend-conversion-traffic-etc/\n",
      "[INFO] Saved extracted article to Netclan20241085.txt\n",
      "[INFO] Processing row 70: URL_ID=Netclan20241086 URL=https://insights.blackcoffer.com/kpi-dashboard-for-accountants/\n",
      "[INFO] Saved extracted article to Netclan20241086.txt\n",
      "[INFO] Processing row 71: URL_ID=Netclan20241087 URL=https://insights.blackcoffer.com/return-on-advertising-spend-dashboard-marketing-automation-and-analytics-using-etl-and-dashboard/\n",
      "[INFO] Saved extracted article to Netclan20241087.txt\n",
      "[INFO] Processing row 72: URL_ID=Netclan20241088 URL=https://insights.blackcoffer.com/ranking-customer-behaviours-for-business-strategy/\n",
      "[INFO] Saved extracted article to Netclan20241088.txt\n",
      "[INFO] Processing row 73: URL_ID=Netclan20241089 URL=https://insights.blackcoffer.com/algorithmic-trading-for-multiple-commodities-markets-like-forex-metals-energy-etc/\n",
      "[INFO] Saved extracted article to Netclan20241089.txt\n",
      "[INFO] Processing row 74: URL_ID=Netclan20241090 URL=https://insights.blackcoffer.com/trading-bot-for-forex/\n",
      "[INFO] Saved extracted article to Netclan20241090.txt\n",
      "[INFO] Processing row 75: URL_ID=Netclan20241091 URL=https://insights.blackcoffer.com/python-model-for-the-analysis-of-sector-specific-stock-etfs-for-investment-purposes%ef%bf%bc/\n",
      "[INFO] Saved extracted article to Netclan20241091.txt\n",
      "[INFO] Processing row 76: URL_ID=Netclan20241092 URL=https://insights.blackcoffer.com/medical-classification/\n",
      "[INFO] Saved extracted article to Netclan20241092.txt\n",
      "[INFO] Processing row 77: URL_ID=Netclan20241093 URL=https://insights.blackcoffer.com/design-develop-bert-question-answering-model-explanations-with-visualization/\n",
      "[INFO] Saved extracted article to Netclan20241093.txt\n",
      "[INFO] Processing row 78: URL_ID=Netclan20241094 URL=https://insights.blackcoffer.com/design-and-develop-solution-to-anomaly-detection-classification-problems/\n",
      "[INFO] Saved extracted article to Netclan20241094.txt\n",
      "[INFO] Processing row 79: URL_ID=Netclan20241095 URL=https://insights.blackcoffer.com/an-etl-solution-for-currency-data-to-google-big-query/\n",
      "[INFO] Saved extracted article to Netclan20241095.txt\n",
      "[INFO] Processing row 80: URL_ID=Netclan20241096 URL=https://insights.blackcoffer.com/etl-and-mlops-infrastructure-for-blockchain-analytics/\n",
      "[INFO] Saved extracted article to Netclan20241096.txt\n",
      "[INFO] Processing row 81: URL_ID=Netclan20241097 URL=https://insights.blackcoffer.com/an-agent-based-model-of-a-virtual-power-plant-vpp/\n",
      "[INFO] Saved extracted article to Netclan20241097.txt\n",
      "[INFO] Processing row 82: URL_ID=Netclan20241098 URL=https://insights.blackcoffer.com/transform-api-into-sdk-library-and-widget/\n",
      "[INFO] Saved extracted article to Netclan20241098.txt\n",
      "[INFO] Processing row 83: URL_ID=Netclan20241099 URL=https://insights.blackcoffer.com/integration-of-a-product-to-a-cloud-based-crm-platform/\n",
      "[INFO] Saved extracted article to Netclan20241099.txt\n",
      "[INFO] Processing row 84: URL_ID=Netclan20241100 URL=https://insights.blackcoffer.com/a-web-based-dashboard-for-the-filtered-data-retrieval-of-land-records/\n",
      "[INFO] Saved extracted article to Netclan20241100.txt\n",
      "[INFO] Processing row 85: URL_ID=Netclan20241101 URL=https://insights.blackcoffer.com/integration-of-video-conferencing-data-to-the-existing-web-app/\n",
      "[INFO] Saved extracted article to Netclan20241101.txt\n",
      "[INFO] Processing row 86: URL_ID=Netclan20241102 URL=https://insights.blackcoffer.com/design-develop-an-app-in-retool-which-shows-the-progress-of-the-added-video/\n",
      "[INFO] Saved extracted article to Netclan20241102.txt\n",
      "[INFO] Processing row 87: URL_ID=Netclan20241103 URL=https://insights.blackcoffer.com/auvik-connectwise-integration-in-grafana/\n",
      "[INFO] Saved extracted article to Netclan20241103.txt\n",
      "[INFO] Processing row 88: URL_ID=Netclan20241104 URL=https://insights.blackcoffer.com/data-integration-and-big-data-performance-using-elk-stack/\n",
      "[INFO] Saved extracted article to Netclan20241104.txt\n",
      "[INFO] Processing row 89: URL_ID=Netclan20241105 URL=https://insights.blackcoffer.com/web-data-connector/\n",
      "[INFO] Saved extracted article to Netclan20241105.txt\n",
      "[INFO] Processing row 90: URL_ID=Netclan20241106 URL=https://insights.blackcoffer.com/an-app-for-updating-the-email-id-of-the-user-and-stripe-refund-tool-using-retool/\n",
      "[INFO] Saved extracted article to Netclan20241106.txt\n",
      "[INFO] Processing row 91: URL_ID=Netclan20241107 URL=https://insights.blackcoffer.com/an-ai-ml-based-web-application-that-detects-the-correctness-of-text-in-a-given-video/\n",
      "[INFO] Saved extracted article to Netclan20241107.txt\n",
      "[INFO] Processing row 92: URL_ID=Netclan20241108 URL=https://insights.blackcoffer.com/website-tracking-and-insights-using-google-analytics-google-tag-manager/\n",
      "[INFO] Saved extracted article to Netclan20241108.txt\n",
      "[INFO] Processing row 93: URL_ID=Netclan20241109 URL=https://insights.blackcoffer.com/dashboard-to-track-the-analytics-of-the-website-using-google-analytics-and-google-tag-manager/\n",
      "[INFO] Saved extracted article to Netclan20241109.txt\n",
      "[INFO] Processing row 94: URL_ID=Netclan20241110 URL=https://insights.blackcoffer.com/power-bi-dashboard-on-operations-transactions-and-marketing-embedding-the-dashboard-to-web-app/\n",
      "[INFO] Saved extracted article to Netclan20241110.txt\n",
      "[INFO] Processing row 95: URL_ID=Netclan20241111 URL=https://insights.blackcoffer.com/nft-data-automation-looksrare-and-etl-tool/\n",
      "[INFO] Saved extracted article to Netclan20241111.txt\n",
      "[INFO] Processing row 96: URL_ID=Netclan20241112 URL=https://insights.blackcoffer.com/optimize-the-data-scraper-program-to-easily-accommodate-large-files-and-solve-oom-errors/\n",
      "[INFO] Saved extracted article to Netclan20241112.txt\n",
      "[INFO] Processing row 97: URL_ID=Netclan20241113 URL=https://insights.blackcoffer.com/making-a-robust-way-to-sync-data-from-airtables-to-mongodb-using-python-etl-solution/\n",
      "[INFO] Saved extracted article to Netclan20241113.txt\n",
      "[INFO] Processing row 98: URL_ID=Netclan20241114 URL=https://insights.blackcoffer.com/incident-duration-prediction-infrastructure-and-real-estate/\n",
      "[INFO] Saved extracted article to Netclan20241114.txt\n",
      "[INFO] Processing row 99: URL_ID=Netclan20241115 URL=https://insights.blackcoffer.com/statistical-data-analysis-of-reinforced-concrete/\n",
      "[INFO] Saved extracted article to Netclan20241115.txt\n",
      "[INFO] Processing row 100: URL_ID=Netclan20241116 URL=https://insights.blackcoffer.com/database-normalization-segmentation-with-google-data-studio-dashboard-insights/\n",
      "[INFO] Saved extracted article to Netclan20241116.txt\n",
      "[INFO] Processing row 101: URL_ID=Netclan20241117 URL=https://insights.blackcoffer.com/power-bi-dashboard-to-drive-insights-from-complex-data-to-generate-business-insights/\n",
      "[INFO] Saved extracted article to Netclan20241117.txt\n",
      "[INFO] Processing row 102: URL_ID=Netclan20241118 URL=https://insights.blackcoffer.com/real-time-dashboard-to-monitor-infrastructure-activity-and-machines/\n",
      "[INFO] Saved extracted article to Netclan20241118.txt\n",
      "[INFO] Processing row 103: URL_ID=Netclan20241119 URL=https://insights.blackcoffer.com/electric-vehicles-ev-load-management-system-to-forecast-energy-demand/\n",
      "[INFO] Saved extracted article to Netclan20241119.txt\n",
      "[INFO] Processing row 104: URL_ID=Netclan20241120 URL=https://insights.blackcoffer.com/power-bi-data-driven-map-dashboard/\n",
      "[INFO] Saved extracted article to Netclan20241120.txt\n",
      "[INFO] Processing row 105: URL_ID=Netclan20241121 URL=https://insights.blackcoffer.com/google-local-service-ads-lsa-leads-dashboard/\n",
      "[INFO] Saved extracted article to Netclan20241121.txt\n",
      "[INFO] Processing row 106: URL_ID=Netclan20241122 URL=https://insights.blackcoffer.com/aws-lex-voice-and-chatbot/\n",
      "[INFO] Saved extracted article to Netclan20241122.txt\n",
      "[INFO] Processing row 107: URL_ID=Netclan20241123 URL=https://insights.blackcoffer.com/metabridges-api-decentraland-integration/\n",
      "[INFO] Saved extracted article to Netclan20241123.txt\n",
      "[INFO] Processing row 108: URL_ID=Netclan20241124 URL=https://insights.blackcoffer.com/microsoft-azure-chatbot-with-luis-language-understanding/\n",
      "[INFO] Saved extracted article to Netclan20241124.txt\n",
      "[INFO] Processing row 109: URL_ID=Netclan20241125 URL=https://insights.blackcoffer.com/impact-of-news-media-and-press-on-innovation-startups-and-investments/\n",
      "[INFO] Saved extracted article to Netclan20241125.txt\n",
      "[INFO] Processing row 110: URL_ID=Netclan20241126 URL=https://insights.blackcoffer.com/aws-quicksight-reporting-dashboard/\n",
      "[INFO] Saved extracted article to Netclan20241126.txt\n",
      "[INFO] Processing row 111: URL_ID=Netclan20241127 URL=https://insights.blackcoffer.com/google-data-studio-dashboard-for-marketing-ads-and-traction-data/\n",
      "[INFO] Saved extracted article to Netclan20241127.txt\n",
      "[INFO] Processing row 112: URL_ID=Netclan20241128 URL=https://insights.blackcoffer.com/gangala-in-e-commerce-big-data-etl-elt-solution-and-data-warehouse/\n",
      "[INFO] Saved extracted article to Netclan20241128.txt\n",
      "[INFO] Processing row 113: URL_ID=Netclan20241129 URL=https://insights.blackcoffer.com/big-data-solution-to-an-online-multivendor-marketplace-ecommerce-business/\n",
      "[INFO] Saved extracted article to Netclan20241129.txt\n",
      "[INFO] Processing row 114: URL_ID=Netclan20241130 URL=https://insights.blackcoffer.com/creating-a-custom-report-and-dashboard-using-the-data-got-from-atera-api/\n",
      "[INFO] Saved extracted article to Netclan20241130.txt\n",
      "[INFO] Processing row 115: URL_ID=Netclan20241131 URL=https://insights.blackcoffer.com/azure-data-lake-and-power-bi-dashboard/\n",
      "[INFO] Saved extracted article to Netclan20241131.txt\n",
      "[INFO] Processing row 116: URL_ID=Netclan20241132 URL=https://insights.blackcoffer.com/google-data-studio-pipeline-with-gcp-mysql/\n",
      "[INFO] Saved extracted article to Netclan20241132.txt\n",
      "[INFO] Processing row 117: URL_ID=Netclan20241133 URL=https://insights.blackcoffer.com/quickbooks-dashboard-to-find-patterns-in-finance-sales-and-forecasts/\n",
      "[INFO] Saved extracted article to Netclan20241133.txt\n",
      "[INFO] Processing row 118: URL_ID=Netclan20241134 URL=https://insights.blackcoffer.com/marketing-sales-and-financial-data-business-dashboard-wink-report/\n",
      "[INFO] Saved extracted article to Netclan20241134.txt\n",
      "[INFO] Processing row 119: URL_ID=Netclan20241135 URL=https://insights.blackcoffer.com/react-native-apps-in-the-development-portfolio/\n",
      "[INFO] Saved extracted article to Netclan20241135.txt\n",
      "[INFO] Processing row 120: URL_ID=Netclan20241136 URL=https://insights.blackcoffer.com/a-leading-firm-website-seo-optimization/\n",
      "[INFO] Saved extracted article to Netclan20241136.txt\n",
      "[INFO] Processing row 121: URL_ID=Netclan20241137 URL=https://insights.blackcoffer.com/a-leading-hospitality-firm-in-the-usa-website-seo-optimization/\n",
      "[INFO] Saved extracted article to Netclan20241137.txt\n",
      "[INFO] Processing row 122: URL_ID=Netclan20241138 URL=https://insights.blackcoffer.com/a-leading-firm-in-the-usa-website-seo-optimization/\n",
      "[INFO] Saved extracted article to Netclan20241138.txt\n",
      "[INFO] Processing row 123: URL_ID=Netclan20241139 URL=https://insights.blackcoffer.com/a-leading-musical-instrumental-website-seo-optimization/\n",
      "[INFO] Saved extracted article to Netclan20241139.txt\n",
      "[INFO] Processing row 124: URL_ID=Netclan20241140 URL=https://insights.blackcoffer.com/a-leading-firm-in-the-usa-seo-and-website-optimization/\n",
      "[INFO] Saved extracted article to Netclan20241140.txt\n",
      "[INFO] Processing row 125: URL_ID=Netclan20241141 URL=https://insights.blackcoffer.com/immigration-datawarehouse-ai-based-recommendations/\n",
      "[INFO] Saved extracted article to Netclan20241141.txt\n",
      "[INFO] Processing row 126: URL_ID=Netclan20241142 URL=https://insights.blackcoffer.com/lipsync-automation-for-celebrities-and-influencers/\n",
      "[INFO] Saved extracted article to Netclan20241142.txt\n",
      "[INFO] Processing row 127: URL_ID=Netclan20241143 URL=https://insights.blackcoffer.com/key-audit-matters-predictive-modeling/\n",
      "[INFO] Saved extracted article to Netclan20241143.txt\n",
      "[INFO] Processing row 128: URL_ID=Netclan20241144 URL=https://insights.blackcoffer.com/splitting-of-songs-into-its-vocals-and-instrumental/\n",
      "[INFO] Saved extracted article to Netclan20241144.txt\n",
      "[INFO] Processing row 129: URL_ID=Netclan20241145 URL=https://insights.blackcoffer.com/ai-and-ml-technologies-to-evaluate-learning-assessments/\n",
      "[INFO] Saved extracted article to Netclan20241145.txt\n",
      "[INFO] Processing row 130: URL_ID=Netclan20241146 URL=https://insights.blackcoffer.com/datawarehouse-and-recommendations-engine-for-airbnb/\n",
      "[INFO] Saved extracted article to Netclan20241146.txt\n",
      "[INFO] Processing row 131: URL_ID=Netclan20241147 URL=https://insights.blackcoffer.com/real-estate-data-warehouse/\n",
      "[INFO] Saved extracted article to Netclan20241147.txt\n",
      "[INFO] Processing row 132: URL_ID=Netclan20241148 URL=https://insights.blackcoffer.com/traction-dashboards-of-marketing-campaigns-and-posts/\n",
      "[INFO] Saved extracted article to Netclan20241148.txt\n",
      "[INFO] Processing row 133: URL_ID=Netclan20241149 URL=https://insights.blackcoffer.com/google-local-service-ads-lsa-data-warehouse/\n",
      "[INFO] Saved extracted article to Netclan20241149.txt\n",
      "[INFO] Processing row 134: URL_ID=Netclan20241150 URL=https://insights.blackcoffer.com/google-local-service-ads-missed-calls-and-messages-automation-tool/\n",
      "[INFO] Saved extracted article to Netclan20241150.txt\n",
      "[INFO] Processing row 135: URL_ID=Netclan20241151 URL=https://insights.blackcoffer.com/marketing-ads-leads-call-status-data-tool-to-bigquery/\n",
      "[INFO] Saved extracted article to Netclan20241151.txt\n",
      "[INFO] Processing row 136: URL_ID=Netclan20241152 URL=https://insights.blackcoffer.com/marketing-analytics-to-automate-leads-call-status-and-reporting/\n",
      "[INFO] Saved extracted article to Netclan20241152.txt\n",
      "[INFO] Processing row 137: URL_ID=Netclan20241153 URL=https://insights.blackcoffer.com/callrail-analytics-leads-report-alert/\n",
      "[INFO] Saved extracted article to Netclan20241153.txt\n",
      "[INFO] Processing row 138: URL_ID=Netclan20241154 URL=https://insights.blackcoffer.com/marketing-automation-tool-to-notify-lead-details-to-clients-over-email-and-phone/\n",
      "[INFO] Saved extracted article to Netclan20241154.txt\n",
      "[INFO] Processing row 139: URL_ID=Netclan20241155 URL=https://insights.blackcoffer.com/data-etl-local-service-ads-leads-to-bigquery/\n",
      "[INFO] Saved extracted article to Netclan20241155.txt\n",
      "[INFO] Processing row 140: URL_ID=Netclan20241156 URL=https://insights.blackcoffer.com/marbles-stimulation-using-python/\n",
      "[INFO] Saved extracted article to Netclan20241156.txt\n",
      "[INFO] Processing row 141: URL_ID=Netclan20241157 URL=https://insights.blackcoffer.com/stocktwits-data-structurization/\n",
      "[INFO] Saved extracted article to Netclan20241157.txt\n",
      "[INFO] Processing row 142: URL_ID=Netclan20241158 URL=https://insights.blackcoffer.com/sentimental-analysis-on-shareholder-letter-of-companies/\n",
      "[INFO] Saved extracted article to Netclan20241158.txt\n",
      "[INFO] Processing row 143: URL_ID=Netclan20241159 URL=https://insights.blackcoffer.com/population-and-community-survey-of-america/\n",
      "[INFO] Saved extracted article to Netclan20241159.txt\n",
      "[INFO] Processing row 144: URL_ID=Netclan20241160 URL=https://insights.blackcoffer.com/google-lsa-api-data-automation-and-dashboarding/\n",
      "[INFO] Saved extracted article to Netclan20241160.txt\n",
      "[INFO] Processing row 145: URL_ID=Netclan20241161 URL=https://insights.blackcoffer.com/healthcare-data-analysis/\n",
      "[INFO] Saved extracted article to Netclan20241161.txt\n",
      "[INFO] Processing row 146: URL_ID=Netclan20241162 URL=https://insights.blackcoffer.com/budget-sales-kpi-dashboard-using-power-bi/\n",
      "[INFO] Saved extracted article to Netclan20241162.txt\n",
      "[INFO] Processing row 147: URL_ID=Netclan20241163 URL=https://insights.blackcoffer.com/amazon-buy-bot-an-automation-ai-tool-to-auto-checkouts/\n",
      "[INFO] Saved extracted article to Netclan20241163.txt\n",
      "[INFO] Saved outputs to Output.csv and Output.xlsx\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
